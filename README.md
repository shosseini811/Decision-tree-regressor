**Summary:**

In this article, we explored the **Decision Tree Regressors** for regression problems and provided a custom Python implementation from scratch. Decision tree regressors are powerful, versatile, and easy-to-understand models that predict continuous target values by recursively partitioning input data based on feature values.

We used the **CART algorithm** and Python libraries, including **NumPy, pandas, and scikit-learn**, to build our custom decision tree regressor. The implementation involved several key functions, such as `_best_split`, `_mse`, `_terminal_node`, and `_split`, which were used to construct the tree, calculate mean squared error, and make predictions.

We applied our custom implementation to the **Boston Housing dataset** and evaluated its performance using the mean squared error metric. The custom implementation can be further improved or adapted for other tasks, and serves as a foundation for understanding the inner workings of decision tree regressors in real-world applications.
